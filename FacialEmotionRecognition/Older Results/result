(python3-env) joao@joao-ubuntu:~/Desktop/FacialEmotionRecognition-master$ python cnn2.py '/home/joao/Desktop/FacialEmotionRecognition-master/ck_90_10.pickle' 
Using TensorFlow backend.
X_train shape: (5291, 100, 100, 1)
5291 train samples
592 test samples
2019-07-16 10:08:36.031006: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-07-16 10:08:36.114471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-16 10:08:36.114930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.40GiB
2019-07-16 10:08:36.114943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-07-16 10:08:36.422956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-16 10:08:36.422982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-07-16 10:08:36.422988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-07-16 10:08:36.423252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7135 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Training on Fold:  1
cnn2.py:156: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  class_weight=class_weights)
Train on 4761 samples, validate on 530 samples
Epoch 1/50
4761/4761 [==============================] - 19s 4ms/step - loss: 0.0026 - acc: 0.1685 - val_loss: 8.7261 - val_acc: 0.1377
Epoch 2/50
4761/4761 [==============================] - 12s 3ms/step - loss: 0.0024 - acc: 0.2317 - val_loss: 9.2033 - val_acc: 0.2094
Epoch 3/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0023 - acc: 0.2794 - val_loss: 2.1402 - val_acc: 0.2075
Epoch 4/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0023 - acc: 0.3067 - val_loss: 3.1620 - val_acc: 0.2717
Epoch 5/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0021 - acc: 0.3367 - val_loss: 2.7232 - val_acc: 0.2528
Epoch 6/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0020 - acc: 0.3800 - val_loss: 3.2146 - val_acc: 0.2925
Epoch 7/50
4761/4761 [==============================] - 12s 3ms/step - loss: 0.0019 - acc: 0.4203 - val_loss: 2.0828 - val_acc: 0.3170
Epoch 8/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0018 - acc: 0.4577 - val_loss: 2.8786 - val_acc: 0.2868
Epoch 9/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0017 - acc: 0.4949 - val_loss: 2.2951 - val_acc: 0.3906
Epoch 10/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0016 - acc: 0.5194 - val_loss: 1.2255 - val_acc: 0.5472
Epoch 11/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0015 - acc: 0.5490 - val_loss: 2.2570 - val_acc: 0.3472
Epoch 12/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0014 - acc: 0.5734 - val_loss: 1.4167 - val_acc: 0.4698
Epoch 13/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0013 - acc: 0.5871 - val_loss: 1.3048 - val_acc: 0.5075
Epoch 14/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0013 - acc: 0.5982 - val_loss: 1.1396 - val_acc: 0.5604
Epoch 15/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0012 - acc: 0.6110 - val_loss: 1.8363 - val_acc: 0.3736
Epoch 16/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0012 - acc: 0.6223 - val_loss: 1.7209 - val_acc: 0.4660
Epoch 17/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0012 - acc: 0.6387 - val_loss: 1.4781 - val_acc: 0.5151
Epoch 18/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0011 - acc: 0.6562 - val_loss: 2.1820 - val_acc: 0.3321
Epoch 19/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0011 - acc: 0.6591 - val_loss: 1.0668 - val_acc: 0.5604
Epoch 20/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0011 - acc: 0.6675 - val_loss: 1.0096 - val_acc: 0.6094
Epoch 21/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0010 - acc: 0.6713 - val_loss: 1.0094 - val_acc: 0.6604
Epoch 22/50
4761/4761 [==============================] - 12s 2ms/step - loss: 0.0010 - acc: 0.6780 - val_loss: 1.3805 - val_acc: 0.5208
Epoch 23/50
4761/4761 [==============================] - 12s 2ms/step - loss: 9.7438e-04 - acc: 0.6883 - val_loss: 0.7404 - val_acc: 0.7189
Epoch 24/50
4761/4761 [==============================] - 12s 2ms/step - loss: 9.4600e-04 - acc: 0.6948 - val_loss: 1.2008 - val_acc: 0.6302
Epoch 25/50
4761/4761 [==============================] - 12s 2ms/step - loss: 9.2247e-04 - acc: 0.6982 - val_loss: 2.1288 - val_acc: 0.4321
Epoch 26/50
4761/4761 [==============================] - 12s 2ms/step - loss: 9.2590e-04 - acc: 0.6992 - val_loss: 0.9749 - val_acc: 0.6717
Epoch 27/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.8508e-04 - acc: 0.7139 - val_loss: 0.9786 - val_acc: 0.6415
Epoch 28/50
4761/4761 [==============================] - 12s 2ms/step - loss: 9.1576e-04 - acc: 0.7003 - val_loss: 0.7579 - val_acc: 0.6849
Epoch 29/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.6711e-04 - acc: 0.7198 - val_loss: 1.5915 - val_acc: 0.5170
Epoch 30/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.4230e-04 - acc: 0.7213 - val_loss: 0.8640 - val_acc: 0.6811
Epoch 31/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.3929e-04 - acc: 0.7196 - val_loss: 0.6586 - val_acc: 0.7472
Epoch 32/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.2680e-04 - acc: 0.7215 - val_loss: 0.8266 - val_acc: 0.7245
Epoch 33/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.0022e-04 - acc: 0.7358 - val_loss: 1.0575 - val_acc: 0.6151
Epoch 34/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.8952e-04 - acc: 0.7383 - val_loss: 1.1259 - val_acc: 0.6509
Epoch 35/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.7097e-04 - acc: 0.7402 - val_loss: 1.1769 - val_acc: 0.6075
Epoch 36/50
4761/4761 [==============================] - 12s 2ms/step - loss: 8.0937e-04 - acc: 0.7341 - val_loss: 0.6539 - val_acc: 0.7830
Epoch 37/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.5506e-04 - acc: 0.7486 - val_loss: 0.7164 - val_acc: 0.7604
Epoch 38/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.2473e-04 - acc: 0.7610 - val_loss: 1.4955 - val_acc: 0.5340
Epoch 39/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.4328e-04 - acc: 0.7534 - val_loss: 0.6204 - val_acc: 0.7792
Epoch 40/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.5077e-04 - acc: 0.7469 - val_loss: 1.0111 - val_acc: 0.6755
Epoch 41/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.1876e-04 - acc: 0.7549 - val_loss: 0.6500 - val_acc: 0.7547
Epoch 42/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.2120e-04 - acc: 0.7532 - val_loss: 0.7033 - val_acc: 0.7491
Epoch 43/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.0223e-04 - acc: 0.7608 - val_loss: 0.7443 - val_acc: 0.7113
Epoch 44/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.3565e-04 - acc: 0.7538 - val_loss: 0.6977 - val_acc: 0.7396
Epoch 45/50
4761/4761 [==============================] - 12s 2ms/step - loss: 7.0562e-04 - acc: 0.7601 - val_loss: 0.7230 - val_acc: 0.7698
Epoch 46/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.8503e-04 - acc: 0.7690 - val_loss: 0.5694 - val_acc: 0.7755
Epoch 47/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.8970e-04 - acc: 0.7671 - val_loss: 0.6811 - val_acc: 0.7528
Epoch 48/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.9581e-04 - acc: 0.7601 - val_loss: 0.7620 - val_acc: 0.7396
Epoch 49/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.8056e-04 - acc: 0.7753 - val_loss: 0.6907 - val_acc: 0.7358
Epoch 50/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.7156e-04 - acc: 0.7719 - val_loss: 1.1110 - val_acc: 0.6377
====================================================================================


Training on Fold:  2
Train on 4761 samples, validate on 530 samples
Epoch 1/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.5013e-04 - acc: 0.7757 - val_loss: 0.7171 - val_acc: 0.7434
Epoch 2/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.3997e-04 - acc: 0.7799 - val_loss: 0.5845 - val_acc: 0.7642
Epoch 3/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.7776e-04 - acc: 0.7732 - val_loss: 0.9809 - val_acc: 0.6868
Epoch 4/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.4507e-04 - acc: 0.7767 - val_loss: 0.9708 - val_acc: 0.6547
Epoch 5/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.4918e-04 - acc: 0.7809 - val_loss: 0.6741 - val_acc: 0.7434
Epoch 6/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.1097e-04 - acc: 0.7866 - val_loss: 0.8042 - val_acc: 0.7151
Epoch 7/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.2086e-04 - acc: 0.7851 - val_loss: 0.7471 - val_acc: 0.7038
Epoch 8/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.3621e-04 - acc: 0.7769 - val_loss: 1.1336 - val_acc: 0.6415
Epoch 9/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.3708e-04 - acc: 0.7874 - val_loss: 0.6635 - val_acc: 0.7491
Epoch 10/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.2180e-04 - acc: 0.7874 - val_loss: 0.8176 - val_acc: 0.7057
Epoch 11/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.2086e-04 - acc: 0.7937 - val_loss: 0.7031 - val_acc: 0.7755
Epoch 12/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.9294e-04 - acc: 0.7921 - val_loss: 0.6203 - val_acc: 0.7623
Epoch 13/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.7460e-04 - acc: 0.8017 - val_loss: 0.7628 - val_acc: 0.7302
Epoch 14/50
4761/4761 [==============================] - 12s 2ms/step - loss: 6.2116e-04 - acc: 0.7935 - val_loss: 0.9242 - val_acc: 0.6981
Epoch 15/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.6950e-04 - acc: 0.7919 - val_loss: 0.6202 - val_acc: 0.7679
Epoch 16/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.8827e-04 - acc: 0.8017 - val_loss: 0.7771 - val_acc: 0.7415
Epoch 17/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.9172e-04 - acc: 0.8009 - val_loss: 0.5962 - val_acc: 0.7868
Epoch 18/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.7931e-04 - acc: 0.7977 - val_loss: 0.8644 - val_acc: 0.7019
Epoch 19/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.8860e-04 - acc: 0.8015 - val_loss: 0.9732 - val_acc: 0.6736
Epoch 20/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.6496e-04 - acc: 0.8032 - val_loss: 0.5537 - val_acc: 0.7868
Epoch 21/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.8357e-04 - acc: 0.7961 - val_loss: 0.5519 - val_acc: 0.7830
Epoch 22/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.8811e-04 - acc: 0.7961 - val_loss: 0.4885 - val_acc: 0.8189
Epoch 23/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.5633e-04 - acc: 0.8055 - val_loss: 0.6277 - val_acc: 0.7755
Epoch 24/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.7248e-04 - acc: 0.8021 - val_loss: 0.4889 - val_acc: 0.8340
Epoch 25/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.5727e-04 - acc: 0.8055 - val_loss: 0.9119 - val_acc: 0.7151
Epoch 26/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.4979e-04 - acc: 0.8045 - val_loss: 0.5252 - val_acc: 0.7981
Epoch 27/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.3366e-04 - acc: 0.8124 - val_loss: 0.6608 - val_acc: 0.7604
Epoch 28/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.3896e-04 - acc: 0.8166 - val_loss: 0.6263 - val_acc: 0.7698
Epoch 29/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.4686e-04 - acc: 0.8093 - val_loss: 0.7534 - val_acc: 0.7038
Epoch 30/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.3985e-04 - acc: 0.8103 - val_loss: 0.6751 - val_acc: 0.7642
Epoch 31/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.8871e-04 - acc: 0.8057 - val_loss: 0.5622 - val_acc: 0.7981
Epoch 32/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.3170e-04 - acc: 0.8147 - val_loss: 0.5126 - val_acc: 0.8057
Epoch 33/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.5838e-04 - acc: 0.8108 - val_loss: 1.0892 - val_acc: 0.6358
Epoch 34/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.0842e-04 - acc: 0.8160 - val_loss: 0.6566 - val_acc: 0.7868
Epoch 35/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.5300e-04 - acc: 0.8154 - val_loss: 0.6509 - val_acc: 0.7585
Epoch 36/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.3554e-04 - acc: 0.8116 - val_loss: 0.4103 - val_acc: 0.8358
Epoch 37/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.8045e-04 - acc: 0.8267 - val_loss: 0.5550 - val_acc: 0.7906
Epoch 38/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.1438e-04 - acc: 0.8171 - val_loss: 0.5137 - val_acc: 0.7925
Epoch 39/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.1859e-04 - acc: 0.8202 - val_loss: 1.3190 - val_acc: 0.6170
Epoch 40/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.2215e-04 - acc: 0.8145 - val_loss: 0.4716 - val_acc: 0.8264
Epoch 41/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.6649e-04 - acc: 0.8351 - val_loss: 0.5913 - val_acc: 0.7943
Epoch 42/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.8957e-04 - acc: 0.8257 - val_loss: 0.4598 - val_acc: 0.8245
Epoch 43/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.1956e-04 - acc: 0.8187 - val_loss: 0.3929 - val_acc: 0.8509
Epoch 44/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.0386e-04 - acc: 0.8200 - val_loss: 0.4841 - val_acc: 0.7906
Epoch 45/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.8390e-04 - acc: 0.8280 - val_loss: 0.4858 - val_acc: 0.8377
Epoch 46/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.1181e-04 - acc: 0.8208 - val_loss: 0.5673 - val_acc: 0.7849
Epoch 47/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.9583e-04 - acc: 0.8259 - val_loss: 0.7451 - val_acc: 0.7453
Epoch 48/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.7856e-04 - acc: 0.8313 - val_loss: 0.4904 - val_acc: 0.8075
Epoch 49/50
4761/4761 [==============================] - 12s 3ms/step - loss: 5.1754e-04 - acc: 0.8261 - val_loss: 0.6087 - val_acc: 0.7792
Epoch 50/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.7027e-04 - acc: 0.8294 - val_loss: 0.6598 - val_acc: 0.7528
====================================================================================


Training on Fold:  3
Train on 4761 samples, validate on 530 samples
Epoch 1/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.1648e-04 - acc: 0.8225 - val_loss: 0.4232 - val_acc: 0.8283
Epoch 2/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.2144e-04 - acc: 0.8183 - val_loss: 0.3453 - val_acc: 0.8774
Epoch 3/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.8830e-04 - acc: 0.8278 - val_loss: 0.5509 - val_acc: 0.8075
Epoch 4/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.9984e-04 - acc: 0.8231 - val_loss: 0.3832 - val_acc: 0.8415
Epoch 5/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.7656e-04 - acc: 0.8334 - val_loss: 0.3871 - val_acc: 0.8585
Epoch 6/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.7671e-04 - acc: 0.8292 - val_loss: 0.4672 - val_acc: 0.8245
Epoch 7/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.8339e-04 - acc: 0.8313 - val_loss: 0.3435 - val_acc: 0.8642
Epoch 8/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.5625e-04 - acc: 0.8355 - val_loss: 0.3679 - val_acc: 0.8604
Epoch 9/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.9071e-04 - acc: 0.8286 - val_loss: 0.4655 - val_acc: 0.8415
Epoch 10/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.5855e-04 - acc: 0.8372 - val_loss: 0.3886 - val_acc: 0.8566
Epoch 11/50
4761/4761 [==============================] - 12s 2ms/step - loss: 5.0001e-04 - acc: 0.8280 - val_loss: 0.4366 - val_acc: 0.8321
Epoch 12/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.8080e-04 - acc: 0.8284 - val_loss: 0.4022 - val_acc: 0.8472
Epoch 13/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.6565e-04 - acc: 0.8320 - val_loss: 0.6700 - val_acc: 0.7698
Epoch 14/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.6753e-04 - acc: 0.8313 - val_loss: 0.4713 - val_acc: 0.8245
Epoch 15/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.7549e-04 - acc: 0.8288 - val_loss: 0.5114 - val_acc: 0.8075
Epoch 16/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.6531e-04 - acc: 0.8307 - val_loss: 0.6409 - val_acc: 0.7717
Epoch 17/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.6759e-04 - acc: 0.8385 - val_loss: 0.3994 - val_acc: 0.8434
Epoch 18/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.6480e-04 - acc: 0.8307 - val_loss: 0.6645 - val_acc: 0.7849
Epoch 19/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.6344e-04 - acc: 0.8360 - val_loss: 0.5678 - val_acc: 0.8245
Epoch 20/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.6051e-04 - acc: 0.8345 - val_loss: 0.4137 - val_acc: 0.8415
Epoch 21/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.5253e-04 - acc: 0.8383 - val_loss: 0.3473 - val_acc: 0.8660
Epoch 22/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.7271e-04 - acc: 0.8345 - val_loss: 0.3863 - val_acc: 0.8585
Epoch 23/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3765e-04 - acc: 0.8389 - val_loss: 0.3680 - val_acc: 0.8717
Epoch 24/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.6453e-04 - acc: 0.8271 - val_loss: 0.3469 - val_acc: 0.8792
Epoch 25/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.7032e-04 - acc: 0.8378 - val_loss: 0.5078 - val_acc: 0.8057
Epoch 26/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3893e-04 - acc: 0.8378 - val_loss: 0.3813 - val_acc: 0.8717
Epoch 27/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.5881e-04 - acc: 0.8318 - val_loss: 0.4264 - val_acc: 0.8283
Epoch 28/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.4054e-04 - acc: 0.8402 - val_loss: 0.3456 - val_acc: 0.8698
Epoch 29/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.4352e-04 - acc: 0.8387 - val_loss: 0.3864 - val_acc: 0.8377
Epoch 30/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.5307e-04 - acc: 0.8326 - val_loss: 0.3941 - val_acc: 0.8547
Epoch 31/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3376e-04 - acc: 0.8416 - val_loss: 0.3178 - val_acc: 0.8736
Epoch 32/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.5268e-04 - acc: 0.8402 - val_loss: 0.4196 - val_acc: 0.8415
Epoch 33/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.5660e-04 - acc: 0.8366 - val_loss: 0.3167 - val_acc: 0.8774
Epoch 34/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.4821e-04 - acc: 0.8418 - val_loss: 0.3615 - val_acc: 0.8509
Epoch 35/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3048e-04 - acc: 0.8378 - val_loss: 0.3390 - val_acc: 0.8698
Epoch 36/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.2338e-04 - acc: 0.8467 - val_loss: 0.3394 - val_acc: 0.8623
Epoch 37/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.4014e-04 - acc: 0.8425 - val_loss: 0.3941 - val_acc: 0.8377
Epoch 38/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.4173e-04 - acc: 0.8448 - val_loss: 0.4560 - val_acc: 0.8491
Epoch 39/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3730e-04 - acc: 0.8439 - val_loss: 0.3509 - val_acc: 0.8472
Epoch 40/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.4147e-04 - acc: 0.8397 - val_loss: 0.4610 - val_acc: 0.8283
Epoch 41/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.4943e-04 - acc: 0.8374 - val_loss: 0.3779 - val_acc: 0.8396
Epoch 42/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.2120e-04 - acc: 0.8448 - val_loss: 0.4200 - val_acc: 0.8358
Epoch 43/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.2151e-04 - acc: 0.8488 - val_loss: 0.3629 - val_acc: 0.8547
Epoch 44/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.2518e-04 - acc: 0.8473 - val_loss: 0.4007 - val_acc: 0.8566
Epoch 45/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.4722e-04 - acc: 0.8360 - val_loss: 0.4119 - val_acc: 0.8377
Epoch 46/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3808e-04 - acc: 0.8431 - val_loss: 0.3495 - val_acc: 0.8604
Epoch 47/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.2529e-04 - acc: 0.8431 - val_loss: 0.4955 - val_acc: 0.8170
Epoch 48/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.2940e-04 - acc: 0.8484 - val_loss: 0.4376 - val_acc: 0.8264
Epoch 49/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.1187e-04 - acc: 0.8475 - val_loss: 0.3304 - val_acc: 0.8528
Epoch 50/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.1422e-04 - acc: 0.8431 - val_loss: 0.5001 - val_acc: 0.8226
====================================================================================


Training on Fold:  4
Train on 4761 samples, validate on 530 samples
Epoch 1/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3702e-04 - acc: 0.8374 - val_loss: 0.4680 - val_acc: 0.8189
Epoch 2/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.4278e-04 - acc: 0.8404 - val_loss: 0.5044 - val_acc: 0.8038
Epoch 3/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.3721e-04 - acc: 0.8456 - val_loss: 0.5094 - val_acc: 0.8132
Epoch 4/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.2823e-04 - acc: 0.8362 - val_loss: 0.7049 - val_acc: 0.7585
Epoch 5/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0150e-04 - acc: 0.8496 - val_loss: 0.4034 - val_acc: 0.8566
Epoch 6/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0176e-04 - acc: 0.8538 - val_loss: 0.5892 - val_acc: 0.7906
Epoch 7/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.3148e-04 - acc: 0.8458 - val_loss: 0.5219 - val_acc: 0.8057
Epoch 8/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.2814e-04 - acc: 0.8433 - val_loss: 0.4129 - val_acc: 0.8358
Epoch 9/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.2653e-04 - acc: 0.8406 - val_loss: 0.4605 - val_acc: 0.8113
Epoch 10/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.1148e-04 - acc: 0.8517 - val_loss: 0.3581 - val_acc: 0.8528
Epoch 11/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9675e-04 - acc: 0.8519 - val_loss: 0.3739 - val_acc: 0.8623
Epoch 12/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.0007e-04 - acc: 0.8488 - val_loss: 0.5661 - val_acc: 0.7906
Epoch 13/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.2324e-04 - acc: 0.8494 - val_loss: 0.4832 - val_acc: 0.8057
Epoch 14/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0258e-04 - acc: 0.8500 - val_loss: 0.4895 - val_acc: 0.8094
Epoch 15/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0164e-04 - acc: 0.8479 - val_loss: 0.4045 - val_acc: 0.8434
Epoch 16/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0359e-04 - acc: 0.8481 - val_loss: 0.3914 - val_acc: 0.8491
Epoch 17/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9362e-04 - acc: 0.8561 - val_loss: 0.3978 - val_acc: 0.8321
Epoch 18/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.1210e-04 - acc: 0.8536 - val_loss: 0.4507 - val_acc: 0.8415
Epoch 19/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.2033e-04 - acc: 0.8477 - val_loss: 0.4537 - val_acc: 0.8208
Epoch 20/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.1324e-04 - acc: 0.8494 - val_loss: 0.5234 - val_acc: 0.8057
Epoch 21/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9483e-04 - acc: 0.8526 - val_loss: 0.6255 - val_acc: 0.7509
Epoch 22/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0719e-04 - acc: 0.8517 - val_loss: 0.3848 - val_acc: 0.8434
Epoch 23/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.8668e-04 - acc: 0.8578 - val_loss: 0.3601 - val_acc: 0.8660
Epoch 24/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.1200e-04 - acc: 0.8507 - val_loss: 0.3194 - val_acc: 0.8925
Epoch 25/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9487e-04 - acc: 0.8513 - val_loss: 0.5663 - val_acc: 0.7660
Epoch 26/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9007e-04 - acc: 0.8551 - val_loss: 0.4940 - val_acc: 0.7981
Epoch 27/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9076e-04 - acc: 0.8547 - val_loss: 0.5415 - val_acc: 0.7887
Epoch 28/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.0408e-04 - acc: 0.8442 - val_loss: 0.4073 - val_acc: 0.8358
Epoch 29/50
4761/4761 [==============================] - 12s 2ms/step - loss: 4.0535e-04 - acc: 0.8555 - val_loss: 0.6850 - val_acc: 0.7642
Epoch 30/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9374e-04 - acc: 0.8523 - val_loss: 0.3834 - val_acc: 0.8358
Epoch 31/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9823e-04 - acc: 0.8500 - val_loss: 0.3798 - val_acc: 0.8547
Epoch 32/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.9850e-04 - acc: 0.8490 - val_loss: 0.5550 - val_acc: 0.7943
Epoch 33/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.0253e-04 - acc: 0.8507 - val_loss: 0.3794 - val_acc: 0.8566
Epoch 34/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7780e-04 - acc: 0.8654 - val_loss: 0.5752 - val_acc: 0.7849
Epoch 35/50
4761/4761 [==============================] - 12s 3ms/step - loss: 4.0442e-04 - acc: 0.8465 - val_loss: 0.3208 - val_acc: 0.8698
Epoch 36/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.8177e-04 - acc: 0.8530 - val_loss: 0.4002 - val_acc: 0.8472
Epoch 37/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.8183e-04 - acc: 0.8622 - val_loss: 0.4819 - val_acc: 0.8226
Epoch 38/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.8585e-04 - acc: 0.8561 - val_loss: 0.4612 - val_acc: 0.8245
Epoch 39/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.8501e-04 - acc: 0.8582 - val_loss: 0.3523 - val_acc: 0.8642
Epoch 40/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.8848e-04 - acc: 0.8526 - val_loss: 0.4624 - val_acc: 0.8151
Epoch 41/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.8685e-04 - acc: 0.8574 - val_loss: 0.3067 - val_acc: 0.8774
Epoch 42/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6627e-04 - acc: 0.8624 - val_loss: 0.4026 - val_acc: 0.8415
Epoch 43/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.8823e-04 - acc: 0.8502 - val_loss: 0.4257 - val_acc: 0.8528
Epoch 44/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7866e-04 - acc: 0.8610 - val_loss: 0.4333 - val_acc: 0.8321
Epoch 45/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.8199e-04 - acc: 0.8595 - val_loss: 0.3523 - val_acc: 0.8585
Epoch 46/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7622e-04 - acc: 0.8620 - val_loss: 0.4501 - val_acc: 0.8075
Epoch 47/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6592e-04 - acc: 0.8664 - val_loss: 0.5617 - val_acc: 0.7887
Epoch 48/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.7901e-04 - acc: 0.8595 - val_loss: 0.3654 - val_acc: 0.8528
Epoch 49/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6149e-04 - acc: 0.8706 - val_loss: 0.4223 - val_acc: 0.8396
Epoch 50/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7217e-04 - acc: 0.8605 - val_loss: 0.4934 - val_acc: 0.8264
====================================================================================


Training on Fold:  5
Train on 4761 samples, validate on 530 samples
Epoch 1/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6959e-04 - acc: 0.8631 - val_loss: 0.3885 - val_acc: 0.8547
Epoch 2/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7994e-04 - acc: 0.8557 - val_loss: 0.4037 - val_acc: 0.8358
Epoch 3/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6225e-04 - acc: 0.8647 - val_loss: 0.3762 - val_acc: 0.8491
Epoch 4/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6214e-04 - acc: 0.8618 - val_loss: 0.3717 - val_acc: 0.8509
Epoch 5/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7638e-04 - acc: 0.8601 - val_loss: 0.3680 - val_acc: 0.8623
Epoch 6/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5076e-04 - acc: 0.8685 - val_loss: 0.3875 - val_acc: 0.8491
Epoch 7/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7444e-04 - acc: 0.8616 - val_loss: 0.3588 - val_acc: 0.8642
Epoch 8/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6034e-04 - acc: 0.8645 - val_loss: 0.3789 - val_acc: 0.8472
Epoch 9/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6913e-04 - acc: 0.8591 - val_loss: 0.3799 - val_acc: 0.8509
Epoch 10/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6136e-04 - acc: 0.8641 - val_loss: 0.5615 - val_acc: 0.7906
Epoch 11/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6773e-04 - acc: 0.8647 - val_loss: 0.3314 - val_acc: 0.8660
Epoch 12/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.9151e-04 - acc: 0.8540 - val_loss: 0.3813 - val_acc: 0.8755
Epoch 13/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6661e-04 - acc: 0.8624 - val_loss: 0.3270 - val_acc: 0.8698
Epoch 14/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.5400e-04 - acc: 0.8673 - val_loss: 0.4071 - val_acc: 0.8509
Epoch 15/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.4887e-04 - acc: 0.8666 - val_loss: 0.4430 - val_acc: 0.8340
Epoch 16/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6750e-04 - acc: 0.8580 - val_loss: 0.3221 - val_acc: 0.8717
Epoch 17/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6862e-04 - acc: 0.8626 - val_loss: 0.5731 - val_acc: 0.7830
Epoch 18/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5939e-04 - acc: 0.8647 - val_loss: 0.3645 - val_acc: 0.8358
Epoch 19/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6553e-04 - acc: 0.8618 - val_loss: 0.3041 - val_acc: 0.8736
Epoch 20/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6440e-04 - acc: 0.8605 - val_loss: 0.3617 - val_acc: 0.8642
Epoch 21/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.4513e-04 - acc: 0.8691 - val_loss: 0.4000 - val_acc: 0.8509
Epoch 22/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5600e-04 - acc: 0.8706 - val_loss: 0.3967 - val_acc: 0.8509
Epoch 23/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5918e-04 - acc: 0.8679 - val_loss: 0.3151 - val_acc: 0.8849
Epoch 24/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7171e-04 - acc: 0.8639 - val_loss: 0.4705 - val_acc: 0.8321
Epoch 25/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.4465e-04 - acc: 0.8689 - val_loss: 0.3321 - val_acc: 0.8698
Epoch 26/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.4058e-04 - acc: 0.8717 - val_loss: 0.3963 - val_acc: 0.8434
Epoch 27/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6186e-04 - acc: 0.8677 - val_loss: 0.3490 - val_acc: 0.8830
Epoch 28/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5527e-04 - acc: 0.8685 - val_loss: 0.3417 - val_acc: 0.8774
Epoch 29/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.7162e-04 - acc: 0.8563 - val_loss: 0.2968 - val_acc: 0.8679
Epoch 30/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.5492e-04 - acc: 0.8677 - val_loss: 0.3721 - val_acc: 0.8585
Epoch 31/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.7884e-04 - acc: 0.8647 - val_loss: 0.4255 - val_acc: 0.8434
Epoch 32/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6819e-04 - acc: 0.8618 - val_loss: 0.3262 - val_acc: 0.8774
Epoch 33/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5807e-04 - acc: 0.8691 - val_loss: 0.3651 - val_acc: 0.8660
Epoch 34/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5289e-04 - acc: 0.8687 - val_loss: 0.3548 - val_acc: 0.8642
Epoch 35/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.4581e-04 - acc: 0.8731 - val_loss: 0.2964 - val_acc: 0.8774
Epoch 36/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.4131e-04 - acc: 0.8759 - val_loss: 0.4453 - val_acc: 0.8340
Epoch 37/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5512e-04 - acc: 0.8641 - val_loss: 0.3675 - val_acc: 0.8566
Epoch 38/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5667e-04 - acc: 0.8664 - val_loss: 0.4023 - val_acc: 0.8547
Epoch 39/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6473e-04 - acc: 0.8635 - val_loss: 0.3926 - val_acc: 0.8415
Epoch 40/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.5004e-04 - acc: 0.8662 - val_loss: 0.3490 - val_acc: 0.8642
Epoch 41/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.6081e-04 - acc: 0.8677 - val_loss: 0.3978 - val_acc: 0.8585
Epoch 42/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.6140e-04 - acc: 0.8666 - val_loss: 0.3783 - val_acc: 0.8642
Epoch 43/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.5829e-04 - acc: 0.8624 - val_loss: 0.4029 - val_acc: 0.8566
Epoch 44/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.4536e-04 - acc: 0.8696 - val_loss: 0.4851 - val_acc: 0.8132
Epoch 45/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.5969e-04 - acc: 0.8662 - val_loss: 0.2839 - val_acc: 0.8981
Epoch 46/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.3513e-04 - acc: 0.8796 - val_loss: 0.4003 - val_acc: 0.8623
Epoch 47/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.4096e-04 - acc: 0.8706 - val_loss: 0.3527 - val_acc: 0.8698
Epoch 48/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.4307e-04 - acc: 0.8712 - val_loss: 0.3403 - val_acc: 0.8755
Epoch 49/50
4761/4761 [==============================] - 12s 3ms/step - loss: 3.2668e-04 - acc: 0.8778 - val_loss: 0.4184 - val_acc: 0.8302
Epoch 50/50
4761/4761 [==============================] - 12s 2ms/step - loss: 3.5102e-04 - acc: 0.8696 - val_loss: 0.3832 - val_acc: 0.8509
====================================================================================


Test score: 0.38316039398031415
Test accuracy: 85.09433953267224
(python3-env) joao@joao-ubuntu:~/Desktop/FacialEmotionRecognition-master$ python test.py '/home/joao/Desktop/FacialEmotionRecognition-master/ck_90_10.pickle' 
Using TensorFlow backend.
2019-07-16 10:58:46.495910: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-07-16 10:58:46.585736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-16 10:58:46.586196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.33GiB
2019-07-16 10:58:46.586211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-07-16 10:58:46.895122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-16 10:58:46.895151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-07-16 10:58:46.895160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-07-16 10:58:46.895422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7069 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
image_array (Conv2D)         (None, 100, 100, 16)      800       
_________________________________________________________________
batch_normalization_1 (Batch (None, 100, 100, 16)      64        
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 100, 100, 16)      12560     
_________________________________________________________________
batch_normalization_2 (Batch (None, 100, 100, 16)      64        
_________________________________________________________________
activation_1 (Activation)    (None, 100, 100, 16)      0         
_________________________________________________________________
average_pooling2d_1 (Average (None, 50, 50, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 50, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 50, 50, 32)        12832     
_________________________________________________________________
batch_normalization_3 (Batch (None, 50, 50, 32)        128       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 50, 50, 32)        25632     
_________________________________________________________________
batch_normalization_4 (Batch (None, 50, 50, 32)        128       
_________________________________________________________________
activation_2 (Activation)    (None, 50, 50, 32)        0         
_________________________________________________________________
average_pooling2d_2 (Average (None, 50, 50, 32)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50, 50, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 50, 50, 64)        18496     
_________________________________________________________________
batch_normalization_5 (Batch (None, 50, 50, 64)        256       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 50, 50, 64)        36928     
_________________________________________________________________
batch_normalization_6 (Batch (None, 50, 50, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 50, 50, 64)        0         
_________________________________________________________________
average_pooling2d_3 (Average (None, 50, 50, 64)        0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50, 50, 64)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 50, 50, 128)       73856     
_________________________________________________________________
batch_normalization_7 (Batch (None, 50, 50, 128)       512       
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 50, 50, 128)       147584    
_________________________________________________________________
batch_normalization_8 (Batch (None, 50, 50, 128)       512       
_________________________________________________________________
activation_4 (Activation)    (None, 50, 50, 128)       0         
_________________________________________________________________
average_pooling2d_4 (Average (None, 25, 25, 128)       0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 25, 25, 128)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 25, 25, 256)       295168    
_________________________________________________________________
batch_normalization_9 (Batch (None, 25, 25, 256)       1024      
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 25, 25, 8)         18440     
_________________________________________________________________
global_average_pooling2d_1 ( (None, 8)                 0         
_________________________________________________________________
predictions (Activation)     (None, 8)                 0         
=================================================================
Total params: 645,240
Trainable params: 643,768
Non-trainable params: 1,472
_________________________________________________________________
(592, 8)
----------------------
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 5 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 5 true value: [0]
predicted: 5 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 5 true value: [0]
predicted: 5 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 7 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 0 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 1 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 4 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 7 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 0 true value: [0]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 0 true value: [1]
predicted: 0 true value: [1]
predicted: 1 true value: [1]
predicted: 0 true value: [1]
predicted: 0 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 0 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 6 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 6 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 7 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 4 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 2 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 1 true value: [1]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 2 true value: [2]
predicted: 3 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 7 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 0 true value: [3]
predicted: 0 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 0 true value: [3]
predicted: 0 true value: [3]
predicted: 0 true value: [3]
predicted: 4 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 4 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 1 true value: [3]
predicted: 0 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 0 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 0 true value: [3]
predicted: 3 true value: [3]
predicted: 0 true value: [3]
predicted: 3 true value: [3]
predicted: 3 true value: [3]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 4 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 7 true value: [4]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 7 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 7 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 4 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 7 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 7 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 0 true value: [5]
predicted: 0 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 0 true value: [5]
predicted: 5 true value: [5]
predicted: 5 true value: [5]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 6 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 0 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 1 true value: [6]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 0 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 4 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 4 true value: [7]
predicted: 4 true value: [7]
predicted: 7 true value: [7]
predicted: 4 true value: [7]
predicted: 7 true value: [7]
predicted: 4 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 4 true value: [7]
predicted: 4 true value: [7]
predicted: 7 true value: [7]
predicted: 1 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 1 true value: [7]
predicted: 1 true value: [7]
predicted: 1 true value: [7]
predicted: 0 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 0 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 1 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 0 true value: [7]
predicted: 0 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
predicted: 7 true value: [7]
54.22297297297297
(python3-env) joao@joao-ubuntu:~/Desktop/FacialEmotionRecognition-master$ 
